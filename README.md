# BhashaCare ğŸ¤  
### A Voice-First Multilingual Web App powered by Sarvam AI

BhashaCare is an experimental voice-first web application that allows users to interact entirely through speech in native Indian languages.

This project explores a full end-to-end voice pipeline:

Speech â†’ Text â†’ Intent â†’ LLM â†’ Text â†’ Speech

The goal was learning-first: understanding browser audio capture, AI speech APIs, async backends, and real deployment flows.

---

## ğŸš€ Live Demo

ğŸ‘‰ https://voice-public-service-navigator.vercel.app/#

---

## âœ¨ Features

- ğŸ¤ Speak in your native Indian language  
- ğŸ§  Automatic Speech Recognition (STT)  
- ğŸ¤– LLM-based response generation  
- ğŸ”Š AI-generated voice reply (TTS)  
- ğŸ’¬ Minimal UI with real-time audio flow  
- ğŸŒ Fully deployed frontend + backend  

No forms.  
Just voice in â†’ voice out.

---

## ğŸ§  Architecture Overview

User Speech
â†“
Browser (MediaRecorder + Web Audio APIs)
â†“
FastAPI Backend
â†“
Sarvam AI STT
â†“
LLM Processing
â†“
Sarvam AI TTS
â†“
Audio Response to User


### Flow Breakdown

1. User speaks in browser  
2. Audio blob captured via MediaRecorder  
3. Blob sent to FastAPI backend  
4. Sarvam AI converts speech â†’ text  
5. LLM generates response  
6. Sarvam AI converts text â†’ speech  
7. Audio streamed back to frontend and played  

---

## ğŸ›  Tech Stack

### Frontend
- React  
- Web Audio API  
- MediaRecorder API  
- Deployed on Vercel  

### Backend
- FastAPI  
- Async pipelines  
- Deployed on Render  

### AI Layer
- Sarvam AI  
  - Speech-to-Text (STT)  
  - Chat / LLM  
  - Text-to-Speech (TTS)  

---

## ğŸ§ª What This Project Explores

- Browser voice capture  
- Audio blob handling  
- STT â†’ LLM â†’ TTS chaining  
- Async FastAPI orchestration  
- Cross-platform deployment (Vercel + Render)  
- Real-time voice UX  

---

## ğŸ— Local Setup

### Prerequisites

- Node.js  
- Python 3.9+  
- Sarvam AI API key  

---

### Frontend

```bash
cd frontend
npm install
npm run dev
```

---

### Backend

```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

Create a .env file:
```bash
SARVAM_API_KEY=your_api_key_here
```


### ğŸ“Œ Why This Exists

This is not a polished production product.

Itâ€™s a learning experiment.

The purpose was to turn documentation into something tangible and understand how real voice systems behave in practice.

Shipping small experiments beats endless planning.

### ğŸŒ± Future Ideas

Conversation memory

Language auto-detection

Better intent routing

Streaming audio responses

Domain-specific assistants

### ğŸ“„ License
```bash
MIT
```
